---
title: GDG DevFest Emilia Romagna 2018
tags: [Conferences, Notes]
style: fill
color: primary
description: A glimpse over the conference contents.
---

![Alt image](https://gabrielecorni.github.io/docs/2018-12-01-gdg-devfest-18/event.png)

Source: [Link to the event](https://devfestemiliaromagna.it "Main Page")

## La Morte Nera, e se fosse prototipizzata con Firebase e React?

Firebase è interessante, ha una versione free (con limiti) e una a pagamento (si paga a richieste e dati trasferiti).

Firestore è un database statico persistente, Firebase ha un database real time in cui è possibile implementare ad esempio una chat online.

Integrazione con React è molto semplice, bastano poche istruzioni, ma mai portare backend già pronto in Firebase: conviene riscrivere/aggiungere incrementalmente particine, con molte funzioni corte e specializzate. 

No merging di dati, parti diverse di app con dipendenze diverse di backend!

## Google Cloud: 101: Architecture and Orchestration

Google Cloud Platform (GCP) ha molte cose (anche Machine Learning!) e billing complesso (ma dettagliato).

Per provarlo il consiglio è di usare [Qwicklabs](https://www.qwiklabs.com/home?locale=en "Qwicklabs"), facendo redeem dei token cartacei forniti.

## ReasonML: enjoy front-end programming again

[Slides](http://illbe.xyz/talks/reasonml/#/ "ReasonML")

[ReasonML](https://reasonml.github.io "Go to GitHub repo") estende OCaml come compilatore JS. Great deal: è "sufficientemente tipato" e ha "integrazione abbastanza facile" con JS nativo. Permette side effects.

La sua forza sono i tipi: non devono essere specificati ma il compilatore riesce ad inferirli e segnalare errori.

La sua debolezza: mancanza di community, spesso è difficile reperire info e soprattutto chiedere consiglio su errori.

A compile time ci si accorge di errori, a runtime (JS) i tipi non esistono più, e si ha garanzia di mancanza di errori a runtime.

## What's new in Tensorflow 2.0

Introdotto Keras ufficialmente (da tf.layers a tf.keras.layers).  

Ma attenzione: non basta fare "find&replace", i nuovi *keras_layers* non sono compatibili con i vecchi *layers* (e.g. tf.layers.Conv2D != tf.keras.layers.Conv2D -> il modello collassa).

Rimosso tf.contrib, cosa buona e giusta.

A default si partirà con grafo dinamico stile PyTorch, ma settando (ahimè) esplicitamente un flag si potrà tornare a grafo statico.

Keras continuerà ad andare uguale se usato alla *"Keras way"* (i suoi layer derivano da tf.NN).

## Continuous Integration and Delivery on Google Cloud

Microservizi è meglio di monolita, ma attenzione: è difficile!

Consiglio: partire da monolita, poi quando funziona man mano aggiungere microservizi.

[Jenkins](https://jenkins.io "Jenkins") è il top, [Spinnaker](https://www.spinnaker.io "Spinnaker"), [Kubernetes](https://kubernetes.io "Kubernetes"), [Digital Ocean](https://www.digitalocean.com "Digital Ocean") sono altre keywords da considerare in ambito [DevOps](https://www.atlassian.com/devops "DevOps") perchè facilitano il ciclo di CI/CD, anche se sono specializzate per pipeline su cloud.

CI/CD **non** eliminano bugs, ma rendono facile trovare quale parte del sw è buggata.

- CI: i commit passano attraverso unit tests, se ok viene creata una nuova immagine nel registry, se fail si fa rollback.
- CD: si mandano online i cambiamenti con "zero downtime". Rolling vs Canary.

## Python Parallel Computing

Per applicazioni IO bound: threading.

Per applicazioni CPU bound: multiprocessing.

    Pool()
    
è il costrutto per gestire pool di thread. Conviene usarlo senza parametro (tanti thread quanti numero di core), ma si può specificare il suo size anche dandogli un numero preciso.

Threading non ha vera concorrenza, perchè il GIL è attivo. Si specifica un timeout con cui il processore fa switch da thread ad altro (o switch automatico se un processo è bloccato in IO), ma tutto esegue nel main process.

Multiprocessing è concorrenza vera, ma ha overhead per la creazione di nuovi processi.

Anche numpy è velocissimo e stra-ottimizzato.

Con queste tecniche i nostri programmi python possono eseguire molto più rapidamente!

**Hint:** come fare per capire quali parti parallelizzare "strategicamente"? Usare un *profiler*! [vprof](https://github.com/nvdv/vprof "vprof") è un ottimo profiler python!

## Event loop tales on I/O bound Node.js applications

[Slides](https://docs.google.com/presentation/d/1jg8uEUNBpJB23QnAKZtOx4rDvAsUeQtEduIoRck1x7Y/preview?slide=id.g45b67bb014_8_258 "Event loop tales")

## BigData? Make it real with Google Cloud Data & AI Platform

Google Cloud Platform ha un ottimo supporto per Data Engineering pipelines.

[Colab](https://colab.research.google.com/ "Colab") è un equivalente di Jupyter Notebook, per eseguire codice e testing rapido.

[Data Studio](https://datastudio.google.com/ "Data Studio") è un tool online di Business Intelligence gratuito e collegabile con molte sorgenti dati.

[Cloud DataPrep](https://cloud.google.com/dataprep/ "DataPrep") è una GUI online in cui pulire, aggregare, interpolare i dati pre-analisi.

[BigQuery](https://cloud.google.com/bigquery/ "BigQuery") è un data warehouse ottimo per fare analytics, con supporto ML.

Caso di successo: cliente vuole monitorare stato delle linee elettriche.

- elicottero vola e filma linee aeree dall'alto.
- i video frame sono scaricati
- rete neurale allenata su Google Cloud fa object detection dei componenti della linea dalle immagini
- bounding box e cropping dei vari componenti (approx. 15/img)
- altra rete neurale, sempre su Google Cloud, identifica lo stato (OK/guasto) di ogni componente

Per Big Data Hadoop, Spark, Kafka e approccio MapReduce in generale rappresentano ancora oggi lo stato dell'arte.

